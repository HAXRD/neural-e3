Logging to ./results/deepq/env=Acrobot-v1-lr=0.001-seed=1
--------------------------------------
| % time spent exploring  | 98       |
| cumulative reward       | -1.8e+03 |
| episodes                | 10       |
| mean 10 episode reward  | -200     |
| mean 100 episode reward | -200     |
| steps                   | 1.8e+03  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| cumulative reward       | -3.8e+03 |
| episodes                | 20       |
| mean 10 episode reward  | -200     |
| mean 100 episode reward | -200     |
| steps                   | 3.8e+03  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| cumulative reward       | -5.8e+03 |
| episodes                | 30       |
| mean 10 episode reward  | -200     |
| mean 100 episode reward | -200     |
| steps                   | 5.8e+03  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| cumulative reward       | -7.8e+03 |
| episodes                | 40       |
| mean 10 episode reward  | -200     |
| mean 100 episode reward | -200     |
| steps                   | 7.8e+03  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| cumulative reward       | -9.8e+03 |
| episodes                | 50       |
| mean 10 episode reward  | -200     |
| mean 100 episode reward | -200     |
| steps                   | 9.8e+03  |
--------------------------------------
---------------------------------------
| % time spent exploring  | 88        |
| cumulative reward       | -1.18e+04 |
| episodes                | 60        |
| mean 10 episode reward  | -200      |
| mean 100 episode reward | -200      |
| steps                   | 1.18e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 86        |
| cumulative reward       | -1.38e+04 |
| episodes                | 70        |
| mean 10 episode reward  | -200      |
| mean 100 episode reward | -200      |
| steps                   | 1.38e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 84        |
| cumulative reward       | -1.58e+04 |
| episodes                | 80        |
| mean 10 episode reward  | -200      |
| mean 100 episode reward | -200      |
| steps                   | 1.58e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 82        |
| cumulative reward       | -1.78e+04 |
| episodes                | 90        |
| mean 10 episode reward  | -200      |
| mean 100 episode reward | -200      |
| steps                   | 1.78e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 80        |
| cumulative reward       | -1.98e+04 |
| episodes                | 100       |
| mean 10 episode reward  | -200      |
| mean 100 episode reward | -200      |
| steps                   | 1.98e+04  |
---------------------------------------
Saving model due to mean reward increase: None -> -200.0
---------------------------------------
| % time spent exploring  | 78        |
| cumulative reward       | -2.18e+04 |
| episodes                | 110       |
| mean 10 episode reward  | -200      |
| mean 100 episode reward | -200      |
| steps                   | 2.18e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 76        |
| cumulative reward       | -2.38e+04 |
| episodes                | 120       |
| mean 10 episode reward  | -200      |
| mean 100 episode reward | -200      |
| steps                   | 2.38e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 74        |
| cumulative reward       | -2.58e+04 |
| episodes                | 130       |
| mean 10 episode reward  | -200      |
| mean 100 episode reward | -200      |
| steps                   | 2.58e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 72        |
| cumulative reward       | -2.78e+04 |
| episodes                | 140       |
| mean 10 episode reward  | -197      |
| mean 100 episode reward | -200      |
| steps                   | 2.78e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 70        |
| cumulative reward       | -2.98e+04 |
| episodes                | 150       |
| mean 10 episode reward  | -200      |
| mean 100 episode reward | -200      |
| steps                   | 2.98e+04  |
---------------------------------------
Saving model due to mean reward increase: -200.0 -> -199.74000549316406
---------------------------------------
| % time spent exploring  | 68        |
| cumulative reward       | -3.18e+04 |
| episodes                | 160       |
| mean 10 episode reward  | -199      |
| mean 100 episode reward | -200      |
| steps                   | 3.18e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 66        |
| cumulative reward       | -3.37e+04 |
| episodes                | 170       |
| mean 10 episode reward  | -192      |
| mean 100 episode reward | -199      |
| steps                   | 3.37e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 65        |
| cumulative reward       | -3.57e+04 |
| episodes                | 180       |
| mean 10 episode reward  | -200      |
| mean 100 episode reward | -199      |
| steps                   | 3.57e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 63        |
| cumulative reward       | -3.77e+04 |
| episodes                | 190       |
| mean 10 episode reward  | -200      |
| mean 100 episode reward | -199      |
| steps                   | 3.77e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 61        |
| cumulative reward       | -3.97e+04 |
| episodes                | 200       |
| mean 10 episode reward  | -200      |
| mean 100 episode reward | -199      |
| steps                   | 3.97e+04  |
---------------------------------------
Saving model due to mean reward increase: -199.74000549316406 -> -198.82000732421875
---------------------------------------
| % time spent exploring  | 59        |
| cumulative reward       | -4.17e+04 |
| episodes                | 210       |
| mean 10 episode reward  | -200      |
| mean 100 episode reward | -199      |
| steps                   | 4.17e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 57        |
| cumulative reward       | -4.37e+04 |
| episodes                | 220       |
| mean 10 episode reward  | -200      |
| mean 100 episode reward | -199      |
| steps                   | 4.37e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 55        |
| cumulative reward       | -4.57e+04 |
| episodes                | 230       |
| mean 10 episode reward  | -200      |
| mean 100 episode reward | -199      |
| steps                   | 4.57e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 53        |
| cumulative reward       | -4.77e+04 |
| episodes                | 240       |
| mean 10 episode reward  | -200      |
| mean 100 episode reward | -199      |
| steps                   | 4.77e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 51        |
| cumulative reward       | -4.97e+04 |
| episodes                | 250       |
| mean 10 episode reward  | -200      |
| mean 100 episode reward | -199      |
| steps                   | 4.97e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 49        |
| cumulative reward       | -5.17e+04 |
| episodes                | 260       |
| mean 10 episode reward  | -200      |
| mean 100 episode reward | -199      |
| steps                   | 5.17e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 47        |
| cumulative reward       | -5.37e+04 |
| episodes                | 270       |
| mean 10 episode reward  | -200      |
| mean 100 episode reward | -200      |
| steps                   | 5.37e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 45        |
| cumulative reward       | -5.57e+04 |
| episodes                | 280       |
| mean 10 episode reward  | -200      |
| mean 100 episode reward | -200      |
| steps                   | 5.57e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 43        |
| cumulative reward       | -5.77e+04 |
| episodes                | 290       |
| mean 10 episode reward  | -200      |
| mean 100 episode reward | -200      |
| steps                   | 5.77e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 41        |
| cumulative reward       | -5.97e+04 |
| episodes                | 300       |
| mean 10 episode reward  | -198      |
| mean 100 episode reward | -200      |
| steps                   | 5.97e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 39        |
| cumulative reward       | -6.16e+04 |
| episodes                | 310       |
| mean 10 episode reward  | -197      |
| mean 100 episode reward | -199      |
| steps                   | 6.16e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 37        |
| cumulative reward       | -6.33e+04 |
| episodes                | 320       |
| mean 10 episode reward  | -166      |
| mean 100 episode reward | -196      |
| steps                   | 6.33e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 36        |
| cumulative reward       | -6.51e+04 |
| episodes                | 330       |
| mean 10 episode reward  | -177      |
| mean 100 episode reward | -194      |
| steps                   | 6.51e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 34        |
| cumulative reward       | -6.69e+04 |
| episodes                | 340       |
| mean 10 episode reward  | -184      |
| mean 100 episode reward | -192      |
| steps                   | 6.69e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 32        |
| cumulative reward       | -6.86e+04 |
| episodes                | 350       |
| mean 10 episode reward  | -173      |
| mean 100 episode reward | -189      |
| steps                   | 6.87e+04  |
---------------------------------------
Saving model due to mean reward increase: -198.82000732421875 -> -184.74000549316406
---------------------------------------
| % time spent exploring  | 31        |
| cumulative reward       | -7.01e+04 |
| episodes                | 360       |
| mean 10 episode reward  | -151      |
| mean 100 episode reward | -185      |
| steps                   | 7.02e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 29        |
| cumulative reward       | -7.16e+04 |
| episodes                | 370       |
| mean 10 episode reward  | -150      |
| mean 100 episode reward | -180      |
| steps                   | 7.17e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 28        |
| cumulative reward       | -7.29e+04 |
| episodes                | 380       |
| mean 10 episode reward  | -128      |
| mean 100 episode reward | -172      |
| steps                   | 7.3e+04   |
---------------------------------------
---------------------------------------
| % time spent exploring  | 27        |
| cumulative reward       | -7.41e+04 |
| episodes                | 390       |
| mean 10 episode reward  | -118      |
| mean 100 episode reward | -164      |
| steps                   | 7.42e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 26        |
| cumulative reward       | -7.54e+04 |
| episodes                | 400       |
| mean 10 episode reward  | -125      |
| mean 100 episode reward | -157      |
| steps                   | 7.54e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 24        |
| cumulative reward       | -7.67e+04 |
| episodes                | 410       |
| mean 10 episode reward  | -129      |
| mean 100 episode reward | -150      |
| steps                   | 7.67e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 23        |
| cumulative reward       | -7.79e+04 |
| episodes                | 420       |
| mean 10 episode reward  | -125      |
| mean 100 episode reward | -146      |
| steps                   | 7.8e+04   |
---------------------------------------
---------------------------------------
| % time spent exploring  | 22        |
| cumulative reward       | -7.92e+04 |
| episodes                | 430       |
| mean 10 episode reward  | -125      |
| mean 100 episode reward | -141      |
| steps                   | 7.93e+04  |
---------------------------------------
Saving model due to mean reward increase: -184.74000549316406 -> -137.60000610351562
---------------------------------------
| % time spent exploring  | 21        |
| cumulative reward       | -8.03e+04 |
| episodes                | 440       |
| mean 10 episode reward  | -112      |
| mean 100 episode reward | -134      |
| steps                   | 8.04e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 19        |
| cumulative reward       | -8.15e+04 |
| episodes                | 450       |
| mean 10 episode reward  | -125      |
| mean 100 episode reward | -129      |
| steps                   | 8.17e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 18        |
| cumulative reward       | -8.27e+04 |
| episodes                | 460       |
| mean 10 episode reward  | -116      |
| mean 100 episode reward | -126      |
| steps                   | 8.28e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 17        |
| cumulative reward       | -8.37e+04 |
| episodes                | 470       |
| mean 10 episode reward  | -98.5     |
| mean 100 episode reward | -120      |
| steps                   | 8.38e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 16        |
| cumulative reward       | -8.48e+04 |
| episodes                | 480       |
| mean 10 episode reward  | -115      |
| mean 100 episode reward | -119      |
| steps                   | 8.5e+04   |
---------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| cumulative reward       | -8.6e+04 |
| episodes                | 490      |
| mean 10 episode reward  | -117     |
| mean 100 episode reward | -119     |
| steps                   | 8.62e+04 |
--------------------------------------
---------------------------------------
| % time spent exploring  | 14        |
| cumulative reward       | -8.71e+04 |
| episodes                | 500       |
| mean 10 episode reward  | -108      |
| mean 100 episode reward | -117      |
| steps                   | 8.72e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 13        |
| cumulative reward       | -8.82e+04 |
| episodes                | 510       |
| mean 10 episode reward  | -114      |
| mean 100 episode reward | -116      |
| steps                   | 8.84e+04  |
---------------------------------------
---------------------------------------
| % time spent exploring  | 12        |
| cumulative reward       | -8.92e+04 |
| episodes                | 520       |
| mean 10 episode reward  | -101      |
| mean 100 episode reward | -113      |
| steps                   | 8.94e+04  |
---------------------------------------
Saving model due to mean reward increase: -137.60000610351562 -> -110.76000213623047
